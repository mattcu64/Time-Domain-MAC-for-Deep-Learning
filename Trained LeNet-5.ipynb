{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST handwritten data from website: http://yann.lecun.com/exdb/mnist/\n",
    "# The data set including 60000 training data / 10000 testing data\n",
    "import sys\n",
    "import gzip, struct\n",
    "import numpy as np\n",
    "\n",
    "def read_data(image,label):\n",
    "    with gzip.open(label) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(image, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return image,label\n",
    "\n",
    "def get_data():\n",
    "    train_img,train_label = read_data('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
    "    test_img,test_label = read_data('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n",
    "    return [train_img,train_label,test_img,test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examples from data set\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X, y, Xt, yt = get_data()\n",
    "def imshow(img, label):\n",
    "    plt.imshow(img.reshape((28,28)),cmap='gray')\n",
    "    plt.title('LABEL:' + label.astype(str))\n",
    "\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.subplot(131)\n",
    "imshow(X[0], y[0])\n",
    "plt.subplot(132)\n",
    "imshow(X[1], y[1])\n",
    "plt.subplot(133)\n",
    "imshow(X[3], y[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Using dataloader from pytorch to do training and testing\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Normalization function\n",
    "def custom_normalization(data, std, mean):\n",
    "    return (data - mean) / std\n",
    "    \n",
    "batch_size = 200\n",
    "kwargs = {}\n",
    "\n",
    "# Get data and normalization\n",
    "X, y, Xt, yt = get_data()\n",
    "mean, std = X.mean(), X.std()\n",
    "X = custom_normalization(X, mean, std)\n",
    "Xt = custom_normalization(Xt, mean, std)\n",
    "\n",
    "# Build Tensor Dataset and Loader\n",
    "train_x, train_y = torch.from_numpy(X.reshape(-1, 1, 28, 28)).float(), torch.from_numpy(y.astype(int))\n",
    "test_x, test_y = torch.from_numpy(Xt.reshape(-1, 1, 28, 28)).float(), torch.from_numpy(yt.astype(int))\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size, **kwargs)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LeNet-5 Convolutional Neural Network\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.conv3 = nn.Conv2d(16,120,5)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Transfer data from 3D to 1D \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 463.376343\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 62.161247\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 22.319952\n",
      "\n",
      "Test set: Average loss: 0.0751, Accuracy: 9786/10000 (97.0000%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 10.970175\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 10.234801\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 16.127041\n",
      "\n",
      "Test set: Average loss: 0.0634, Accuracy: 9804/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 11.181713\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 6.111042\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 18.435699\n",
      "\n",
      "Test set: Average loss: 0.0426, Accuracy: 9857/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 12.591546\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 9.279142\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 19.633623\n",
      "\n",
      "Test set: Average loss: 0.0418, Accuracy: 9863/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 16.172068\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 4.249102\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.886302\n",
      "\n",
      "Test set: Average loss: 0.0411, Accuracy: 9871/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.935467\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 1.074080\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 3.924234\n",
      "\n",
      "Test set: Average loss: 0.0351, Accuracy: 9888/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 8.362203\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.717822\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.257541\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 9885/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.408460\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 5.512871\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.239725\n",
      "\n",
      "Test set: Average loss: 0.0469, Accuracy: 9856/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.598767\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.687578\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 6.090524\n",
      "\n",
      "Test set: Average loss: 0.0366, Accuracy: 9892/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.649924\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.125252\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 5.536891\n",
      "\n",
      "Test set: Average loss: 0.0475, Accuracy: 9857/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 5.387169\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 0.588598\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 0.520776\n",
      "\n",
      "Test set: Average loss: 0.0386, Accuracy: 9903/10000 (99.0000%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.717863\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 3.954033\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 2.678024\n",
      "\n",
      "Test set: Average loss: 0.0398, Accuracy: 9903/10000 (99.0000%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.680543\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 0.470843\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 0.425633\n",
      "\n",
      "Test set: Average loss: 0.0397, Accuracy: 9902/10000 (99.0000%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.298635\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 0.385841\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 7.034836\n",
      "\n",
      "Test set: Average loss: 0.0467, Accuracy: 9874/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 4.300864\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 0.611502\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 5.034753\n",
      "\n",
      "Test set: Average loss: 0.0376, Accuracy: 9916/10000 (99.0000%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.154089\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 0.057361\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 0.547695\n",
      "\n",
      "Test set: Average loss: 0.0530, Accuracy: 9892/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 3.655542\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 0.283970\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 0.263675\n",
      "\n",
      "Test set: Average loss: 0.0436, Accuracy: 9890/10000 (98.0000%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 6.513569\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 0.911922\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 0.279171\n",
      "\n",
      "Test set: Average loss: 0.0433, Accuracy: 9909/10000 (99.0000%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.152665\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 0.401530\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 0.017469\n",
      "\n",
      "Test set: Average loss: 0.0484, Accuracy: 9896/10000 (98.0000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "\n",
    "# Using Cross Entropy Loss as loss function\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "# Using ADAM as optimizer method\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "\n",
    "# Weight initialization\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        import math\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "model.apply(weight_init)\n",
    "\n",
    "# Training part \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad() # Gradient initialization\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "# Testing part\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "for epoch in range(1,20):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'conv3.weight', 'conv3.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Parameters\n",
    "trained_dict = model.state_dict()\n",
    "trained_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = trained_dict['conv1.weight']\n",
    "w1 = w1.numpy().reshape(6,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('w1.txt','w')\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            file.writelines(w1[i][j][k].astype(str))\n",
    "            file.write(' ')\n",
    "        file.write('\\n')\n",
    "    file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6, 5, 5)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = trained_dict['conv2.weight']\n",
    "w2 = w2.numpy()\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('w2.txt','w')\n",
    "for i in range(16):\n",
    "    for j in range(6):\n",
    "        for k in range(5):\n",
    "            for z in range(5):\n",
    "                file.writelines(w2[i][j][k][z].astype(str))\n",
    "                file.write(' ')\n",
    "            file.write('\\n')\n",
    "        file.write('\\n')\n",
    "    file.write('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 16, 5, 5)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3 = trained_dict['conv3.weight']\n",
    "w3 = w3.numpy()\n",
    "w3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('w3.txt','w')\n",
    "for i in range(120):\n",
    "    for j in range(16):\n",
    "        for k in range(5):\n",
    "            for z in range(5):\n",
    "                file.writelines(w3[i][j][k][z].astype(str))\n",
    "                file.write(' ')\n",
    "            file.write('\\n')\n",
    "        file.write('\\n')\n",
    "    file.write('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 120)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4 = trained_dict['fc1.weight']\n",
    "w4 = w4.numpy()\n",
    "w4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('w4.txt','w')\n",
    "for i in range(84):\n",
    "    for j in range(120):\n",
    "        file.writelines(w4[i][j].astype(str))\n",
    "        file.write(' ')\n",
    "    file.write('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 84)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w5 = trained_dict['fc2.weight']\n",
    "w5 = w5.numpy()\n",
    "w5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('w5.txt','w')\n",
    "for i in range(10):\n",
    "    for j in range(84):\n",
    "        file.writelines(w5[i][j].astype(str))\n",
    "        file.write(' ')\n",
    "    file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = trained_dict['conv1.bias']\n",
    "b1 = b1.numpy()\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = trained_dict['conv2.bias']\n",
    "b2 = b2.numpy()\n",
    "b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3 = trained_dict['conv3.bias']\n",
    "b3 = b3.numpy()\n",
    "b3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b4 = trained_dict['fc1.bias']\n",
    "b4 = b4.numpy()\n",
    "b4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b5 = trained_dict['fc2.bias']\n",
    "b5 = b5.numpy()\n",
    "b5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('bias.txt','w')\n",
    "for i in range(6):\n",
    "    file.writelines(b1[i].astype(str))\n",
    "    file.write(' ')\n",
    "file.write('\\n\\n')\n",
    "for i in range(16):\n",
    "    file.writelines(b2[i].astype(str))          \n",
    "    file.write(' ')\n",
    "file.write('\\n\\n')\n",
    "for i in range(120):\n",
    "    file.writelines(b3[i].astype(str))\n",
    "    file.write(' ')\n",
    "file.write('\\n\\n')\n",
    "for i in range(84):\n",
    "    file.writelines(b4[i].astype(str))     \n",
    "    file.write(' ')\n",
    "file.write('\\n\\n')\n",
    "for i in range(10):\n",
    "    file.writelines(b5[i].astype(str))      \n",
    "    file.write(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxxxxx1, xxxxxx2, xxxxxx3, xxxxxx4 = get_data()\n",
    "xxxxxx3[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('image.txt','w')\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        file.writelines(xxxxxx3[0][i][j].astype(str))\n",
    "        file.write(' ')\n",
    "    file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
