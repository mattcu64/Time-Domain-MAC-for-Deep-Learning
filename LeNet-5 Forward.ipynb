{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import image from 'image.txt'\n",
    "f = open(\"image.txt\")\n",
    "line = f.readline()\n",
    "data_list = []\n",
    "while line:\n",
    "    num = list(map(float,line.split()))\n",
    "    data_list.append(num)\n",
    "    line = f.readline()\n",
    "f.close()\n",
    "image = np.array(data_list)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10f026320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_dict=torch.load('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "mean, std = image.mean(), image.std()\n",
    "norm_image = (image - mean) / std\n",
    "norm_image = norm_image.reshape(1,28,28)\n",
    "norm_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer\n",
    "def conv(A_prev, W, b, pad):   \n",
    "    (n_C_prev, n_H_prev, n_W_prev) = A_prev.shape # Retrieve dimensions\n",
    "    (n_C, n_C_prev, n_f, n_f) = W.shape # Retrieve dimensions\n",
    "    n_H = int((n_H_prev - n_f + 2*pad))+1 # Compute kernel width\n",
    "    n_W =  int((n_W_prev - n_f + 2*pad))+1 # Compute kernel height\n",
    "    Z = np.zeros((n_C, n_H, n_W)) # Initialize output tensor with zeros\n",
    "    A_prev_pad = np.pad(A_prev,((0,0),(pad,pad),(pad,pad)),'constant')# Pad input activation maps\n",
    "\n",
    "    for h in range(n_H):               # height loop\n",
    "        for w in range(n_W):          # width loop\n",
    "            for c in range(n_C):       # channel (# of filter) loop\n",
    "                h_range = slice(h, h+n_f)\n",
    "                w_range = slice(w, w+n_f)\n",
    "                a_slice_prev = A_prev_pad[:, h_range, w_range] # slice of a_prev_pad\n",
    "                Z[c, h, w] = np.sum(a_slice_prev*W[c,:,:,:])+b[c]     \n",
    "\n",
    "    assert(Z.shape == (n_C, n_H, n_W))\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU\n",
    "def relu(A_prev):\n",
    "    (n_C_prev, n_H_prev, n_W_prev) = A_prev.shape\n",
    "    R = np.zeros((n_C_prev, n_H_prev, n_W_prev)) \n",
    "    R = np.where(A_prev >= 0, A_prev, 0)\n",
    "    assert(R.shape == (n_C_prev, n_H_prev, n_W_prev))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling layer forward propagation\n",
    "def maxpool(A_prev, n_f, stride):\n",
    "    (n_C_prev, n_H_prev, n_W_prev) = A_prev.shape # Retrieve dimensions\n",
    "    n_H = int(1 + (n_H_prev-n_f)/stride) # output dimensions\n",
    "    n_W =  int(1 + (n_W_prev-n_f)/stride)  # output dimensions\n",
    "    n_C = n_C_prev # output dimensions\n",
    "    A = np.zeros((n_C, n_H,n_W)) # init output           \n",
    "    \n",
    "    for h in range(n_H):              # height loop\n",
    "            for w in range(n_W):          # width loop\n",
    "                for c in range(n_C):      # channel loop\n",
    "                    h_range = slice(h*stride, h*stride+n_f)\n",
    "                    w_range = slice(w*stride, w*stride+n_f)\n",
    "                    a_prev_slice = A_prev[c, h_range, w_range] # c-th channel slice of i-th sample of A_prev\n",
    "                    A[c, h, w] = np.max(a_prev_slice)\n",
    "                    \n",
    "    assert(A.shape == (n_C, n_H, n_W))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_flat_features\n",
    "def num_flat_features(self, x):\n",
    "    size = x.size()[1:]\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional Layer 1 \n",
    "w1 = model_dict['conv1.weight'].numpy()\n",
    "b1 = model_dict['conv1.bias'].numpy()\n",
    "Z1_conv = conv(norm_image, w1, b1, 2)\n",
    "Z1_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ReLu\n",
    "Z1_relu = relu(Z1_conv)\n",
    "Z1_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 14, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max-pooling \n",
    "Z1_MP = maxpool(Z1_relu, 2, 2)\n",
    "Z1_MP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional Layer 2\n",
    "w2 = model_dict['conv2.weight'].numpy()\n",
    "b2 = model_dict['conv2.bias'].numpy()\n",
    "Z2_conv = conv(Z1_MP, w2, b2, 0)\n",
    "Z2_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ReLu\n",
    "Z2_relu = relu(Z2_conv)\n",
    "Z2_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max-pooling \n",
    "Z2_MP = maxpool(Z2_relu, 2, 2)\n",
    "Z2_MP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional Layer 3\n",
    "w3 = model_dict['conv3.weight'].numpy()\n",
    "b3 = model_dict['conv3.bias'].numpy()\n",
    "Z3_conv = conv(Z2_MP, w3, b3, 0)\n",
    "Z3_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1, 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ReLU\n",
    "Z3_relu = relu(Z3_conv)\n",
    "Z3_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_FC = Z3_relu.reshape(120)\n",
    "input_FC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fully Connection Layer 1 \n",
    "w4 = model_dict['fc1.weight'].numpy()\n",
    "b4 = model_dict['fc1.bias'].numpy()\n",
    "Z4 = input_FC @ w4.T + b4\n",
    "Z4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReLU\n",
    "Z4_relu = np.where(Z4 >= 0, Z4, 0)\n",
    "Z4_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.61500208, -0.64210146, -2.47023386, -5.23282189, -0.35078947,\n",
       "       -6.80284897, -7.33438541,  8.95710866, -9.52891523, -5.31731692])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fully Connection Layer 2\n",
    "w5 = model_dict['fc2.weight'].numpy()\n",
    "b5 = model_dict['fc2.bias'].numpy()\n",
    "Z5 = Z4_relu @ w5.T + b5\n",
    "Z5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Z5.tolist().index(max(Z5))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Download MNIST handwritten data from website: http://yann.lecun.com/exdb/mnist/\n",
    "# The data set including 60000 training data / 10000 testing data\n",
    "import sys\n",
    "import gzip, struct\n",
    "import numpy as np\n",
    "\n",
    "def read_data(image,label):\n",
    "    with gzip.open(label) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(image, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return image,label\n",
    "\n",
    "def get_data():\n",
    "    train_img,train_label = read_data('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
    "    test_img,test_label = read_data('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n",
    "    return [train_img,train_label,test_img,test_label]\n",
    "\n",
    "def custom_normalization(data, std, mean):\n",
    "    return (data - mean) / std\n",
    "    \n",
    "# Get data and normalization\n",
    "X, y, Xt, yt = get_data()\n",
    "mean, std = X.mean(), X.std()\n",
    "X = custom_normalization(X, mean, std)\n",
    "Xt = custom_normalization(Xt, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "9.42609691619873\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "correct = 0 \n",
    "w1 = model_dict['conv1.weight'].numpy()\n",
    "b1 = model_dict['conv1.bias'].numpy()\n",
    "w2 = model_dict['conv2.weight'].numpy()\n",
    "b2 = model_dict['conv2.bias'].numpy()\n",
    "w3 = model_dict['conv3.weight'].numpy()\n",
    "b3 = model_dict['conv3.bias'].numpy()\n",
    "w4 = model_dict['fc1.weight'].numpy()\n",
    "b4 = model_dict['fc1.bias'].numpy()\n",
    "w5 = model_dict['fc2.weight'].numpy()\n",
    "b5 = model_dict['fc2.bias'].numpy()\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    image = Xt[i].reshape(1,28,28)\n",
    "    \n",
    "    Z1_conv = conv(image, w1, b1, 2)\n",
    "    Z1_relu = relu(Z1_conv)\n",
    "    Z1_MP = maxpool(Z1_relu, 2, 2)\n",
    "\n",
    "    Z2_conv = conv(Z1_MP, w2, b2, 0)\n",
    "    Z2_relu = relu(Z2_conv)\n",
    "    Z2_MP = maxpool(Z2_relu, 2, 2)\n",
    "\n",
    "    Z3_conv = conv(Z2_MP, w3, b3, 0)\n",
    "    Z3_relu = relu(Z3_conv)\n",
    "\n",
    "    input_FC = Z3_relu.reshape(120)\n",
    "\n",
    "    Z4 = input_FC @ w4.T + b4\n",
    "    Z4_relu = np.where(Z4 >= 0, Z4, 0)\n",
    "\n",
    "    Z5 = Z4_relu @ w5.T + b5\n",
    "    Y = Z5.tolist().index(max(Z5))\n",
    "    \n",
    "    if Y == yt[i]:\n",
    "        correct += 1 \n",
    "print(correct)\n",
    "\n",
    "end = time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
